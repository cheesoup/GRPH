<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://0.0.0.0:4000/GRPH/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://0.0.0.0:4000/GRPH/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:4000/GRPH/" rel="alternate" type="text/html" /><updated>2021-12-07T23:26:08-05:00</updated><id>http://0.0.0.0:4000/GRPH/feed.xml</id><title type="html">thesis? idk?</title><subtitle>a blog for 4th year workshop at OCADU</subtitle><author><name>Chris Carin</name></author><entry><title type="html">Anti-Aliased Oscillators</title><link href="http://0.0.0.0:4000/GRPH/audio/2021/12/06/antialiased-oscillators.html" rel="alternate" type="text/html" title="Anti-Aliased Oscillators" /><published>2021-12-06T00:00:00-05:00</published><updated>2021-12-06T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/audio/2021/12/06/antialiased-oscillators</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/audio/2021/12/06/antialiased-oscillators.html">&lt;p&gt;I mentioned in a previous post how naively generating waveforms digitally can result in unwanted distortion. The distortion is caused by a phenomenon known as fold-over aliasing and is often the reason why older implementations of digital oscillators sound ‘cheap’. To handle fold-over, I’ve incorporated two algorithms within my oscillators which have proven effective when working in PureData. The first is a well-known algorithm known as PolyBLEP. The second is a bit of an obscure one dubbed ‘Frequency Dithering’.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#sweep-naive-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/sweep_naive.png&quot; alt=&quot;Spectrogram of a non-bandlimited sawtooth sweep from 0 to Nyquist&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Spectrogram of a non-bandlimited sawtooth sweep from 0 to Nyquist
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;sweep-naive-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/sweep_naive.png&quot; alt=&quot;Spectrogram of a non-bandlimited sawtooth sweep from 0 to Nyquist&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed audio&quot; style=&quot;width: &quot;&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/sweep_naive.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;figcaption&gt;Naive Sawtooth Sweep&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;polybleps&quot;&gt;PolyBLEPs&lt;/h2&gt;

&lt;p&gt;The PolyBLEP algorithm is part of a family of BLIT/BLEP algorithms. The idea behind BLITs/BLEPs is to smooth out discontinuities using bandlimited functions. The PolyBLEP in particular is named so due to its use of a &lt;a href=&quot;https://www.scribd.com/document/85351585/Computation-Ally-Effective-Methods-of-Sound-Synthesis&quot;&gt;polynomial bandlimited step function&lt;/a&gt; to achieve this. All this really means is two things: 1) it makes use of one of those math problems from high school that you can solve using the quadratic formula, 2) this math problem is limited in the frequency band it can produce. Below is a spectrogram of a Sawtooth sweep using PolyBLEP Aliasing. While not perfect, PolyBLEPs are extremely effective at reducing fold-over to say the least.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#sweep-blep-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/sweep_blep.png&quot; alt=&quot;Spectrogram of a Sawtooth Sweep w/ PolyBLEP Anti-Aliasing&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Spectrogram of a Sawtooth Sweep w/ PolyBLEP Anti-Aliasing
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;sweep-blep-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/sweep_blep.png&quot; alt=&quot;Spectrogram of a Sawtooth Sweep w/ PolyBLEP Anti-Aliasing&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed audio&quot; style=&quot;width: &quot;&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/sweep_blep.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;figcaption&gt;Sawtooth Sweep w/ Anti-Aliasing&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;My implementation is primarily based on a blog post by &lt;a href=&quot;http://www.martin-finke.de/blog/articles/audio-plugins-018-polyblep-oscillator/&quot;&gt;Martin Finke&lt;/a&gt; which in turn is based on a &lt;a href=&quot;https://www.kvraudio.com/forum/viewtopic.php?t=375517&quot;&gt;KVRforums thread&lt;/a&gt;. As mentioned above, PolyBLEPs make use of a polynomial to smooth out discontinuities within a periodic waveform. To make use of PolyBLEPs, we first need to synthesize a waveform with discontinuities. The simplest way to do this is with a sawtooth wave.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;c1&quot;&gt;// Change in phase for the current.&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frequency&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Phase of the oscillator at the current sample index&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current_sample_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Sample value&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The discontinuity within a sawtooth wave lies within it’s transition from -1 to 1. This normally occurs when waveform’s phase counter jumps from 1 back down to 0. To smooth the discontinuity, we create a function too check the current phase position relative the phase reset point. If the phase is between &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt;, we return &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2 * (phase - phase^2/2 - 0.5)&lt;/code&gt;. If it is between &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1 - delta&lt;/code&gt;, we instead return &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2 * (phase^2/2 + phase + 0.5)&lt;/code&gt;. If it isn’t within range of either, we output 0. The result of the function is then subtracted from the original sawtooth wave. Below is how this function is implemented in the original KVR thread. While &lt;a href=&quot;https://github.com/cheesoup/CheeseVA/blob/b403b30badaec110a6298c1580ad2d2e85ccac06/BasicWaves.cpp#L167&quot;&gt;my implementation&lt;/a&gt; isn’t much different, I think the original is more elegant to read.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;polyBLEP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// 0 &amp;lt;= t &amp;lt; 1&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// -1 &amp;lt; t &amp;lt; 0&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// 0 otherwise&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;polyBLEP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;frequency-dithering&quot;&gt;Frequency Dithering&lt;/h2&gt;

&lt;p&gt;From what I can tell, frequency dithering was initially implemented by &lt;a href=&quot;https://www.youtube.com/channel/UC84u8v2FyqmXjSxYh1d7PRQ&quot;&gt;Scott ‘Acriel’ Nordlund&lt;/a&gt; in PureData. While not an algorithm for reducing aliasing perse, frequency dithering shapes harmonics which have folded over into something a bit more tolerable. Below is a spectrogram of a sawtooth sweep which makes uses of frequency dithering. In contrast to the PolyBLEP spectrogram, it is much noisier. However, there is no perceivable fold-over past a certain threshold.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#sweep-dither-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/sweep_dither.png&quot; alt=&quot;Spectrogram of a Sawtooth Sweep w/ Frequency Dithering&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Spectrogram of a Sawtooth Sweep w/ Frequency Dithering
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;sweep-dither-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/sweep_dither.png&quot; alt=&quot;Spectrogram of a Sawtooth Sweep w/ Frequency Dithering&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed audio&quot; style=&quot;width: &quot;&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/sweep_dither.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;figcaption&gt;Sawtooth Sweep w/ Frequency Dithering&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The idea behind frequency dithering revolves around translating an oscillator’s frequency to integer ratios of the sample rate (i.e. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x / 44100&lt;/code&gt; where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; is a whole number) prior to the calculation of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delta&lt;/code&gt;. This has the effect of causing harmonic partials above Nyquist to re-align with the harmonic series (integer ratios of the base frequency) at the cost of tuning inaccuracies. To fix these inaccuracies, we can generate an average frequency by calculating the two closest frequencies to a target frequency given the above restrictions and rapidly modulate between them.&lt;/p&gt;

&lt;p&gt;Below is my implementation of the frequency dithering in C++. Prior to calculating frequencies, we check if the target frequency is 0. If it is, we skip the whole process and output 0. Otherwise, the first of the pair of frequencies is generated by dividing the sample rate by the incoming frequency, flooring it, and then dividing the sample rate by the result. The second frequency is found the same way except prior to dividing the sample rate, we add one to the floored ratio. To decide which of the two frequencies to output, we calculated the difference of both frequencies and the target frequency. Using that information, we then performed a weighted coin-flip to choose.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// Find the two closest integer ratios for samplerate/frequency&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_d0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_d1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// Dither between the two using a weighted random roll&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_d0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_d1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_d0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fast_rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_d0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_d1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// If the given frequency is 0, return 0;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;The resulting spectrogram when combining the two algorithms can be seen below. I’ve also added some audio examples to demonstrate these methods in action. Together, the algorithms provide a strong basis for keeping fold-over at bay. What’s neat about PolyBLEPs and frequency dithering are how lightweight yet effective they are. When programming for Bela, efficiency is important due to the limited amount of system resources.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#sweep-ditherblep-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/sweep_ditherblep.png&quot; alt=&quot;Sawtooth Sweep w/ Frequency Dithering &amp;amp; PolyBLEP Anti-aliasing&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Sawtooth Sweep w/ Frequency Dithering &amp;amp; PolyBLEP Anti-aliasing
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;sweep-ditherblep-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/sweep_ditherblep.png&quot; alt=&quot;Sawtooth Sweep w/ Frequency Dithering &amp;amp; PolyBLEP Anti-aliasing&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed audio&quot; style=&quot;width: &quot;&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/sweep_ditherblep.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;figcaption&gt;Sawtooth Sweep w/ Frequency Dithering and PolyBLEP Anti-Aliasing&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;</content><author><name>Chris Carin</name></author><category term="Audio" /><category term="Programming" /><category term="Oscillators" /><category term="Bela" /><summary type="html">I mentioned in a previous post how naively generating waveforms digitally can result in unwanted distortion. The distortion is caused by a phenomenon known as fold-over aliasing and is often the reason why older implementations of digital oscillators sound ‘cheap’. To handle fold-over, I’ve incorporated two algorithms within my oscillators which have proven effective when working in PureData. The first is a well-known algorithm known as PolyBLEP. The second is a bit of an obscure one dubbed ‘Frequency Dithering’.</summary></entry><entry><title type="html">CheeseVA Demo Footage!</title><link href="http://0.0.0.0:4000/GRPH/audio/2021/12/05/CheeseVA-Demo-Footage.html" rel="alternate" type="text/html" title="CheeseVA Demo Footage!" /><published>2021-12-05T00:00:00-05:00</published><updated>2021-12-05T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/audio/2021/12/05/CheeseVA-Demo-Footage</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/audio/2021/12/05/CheeseVA-Demo-Footage.html">&lt;p&gt;I just realized I had no actual footage of my sound engine on this blog. I guess better late than never. The overall signal path is still subject to change but most of the oscillator features are more or less finalized at this point. It may take a few posts to fully go over how just the oscillators work. The source code for the engine can be found &lt;a href=&quot;https://github.com/cheesoup/CheeseVA&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;!-- Include for Video Embedding --&gt;
&lt;!-- https://github.com/nathancy/jekyll-embed-video#responsive-videos --&gt;
&lt;div class=&quot;float&quot;&gt;
  &lt;figure class=&quot;embed video&quot;&gt;
    &lt;span class=&quot;video&quot;&gt;
      &lt;iframe style=&quot;width:100%; height:100%;&quot; src=&quot;https://player.vimeo.com/video/653644087?h=b0a124d5cc&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; loading=&quot;lazy&quot; allowfullscreen=&quot;&quot;&gt;
      &lt;/iframe&gt;
    &lt;/span&gt;
    &lt;figcaption class=&quot;caption&quot;&gt;Demo footage the CheeseVA engine so far&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;</content><author><name>Chris Carin</name></author><category term="Audio" /><category term="Updates" /><category term="Bela" /><category term="Demo" /><summary type="html">I just realized I had no actual footage of my sound engine on this blog. I guess better late than never. The overall signal path is still subject to change but most of the oscillator features are more or less finalized at this point. It may take a few posts to fully go over how just the oscillators work. The source code for the engine can be found here.</summary></entry><entry><title type="html">sade is waifu</title><link href="http://0.0.0.0:4000/GRPH/misc/2021/12/05/sade-is-waifu.html" rel="alternate" type="text/html" title="sade is waifu" /><published>2021-12-05T00:00:00-05:00</published><updated>2021-12-05T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/misc/2021/12/05/sade-is-waifu</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/misc/2021/12/05/sade-is-waifu.html">&lt;p&gt;If you don’t like this song, your life choices are incorrect.
&lt;!-- Include Video Embedding --&gt;
&lt;!-- https://github.com/nathancy/jekyll-embed-video#responsive-videos --&gt;&lt;/p&gt;
&lt;div class=&quot;float&quot;&gt;
  &lt;figure class=&quot;embed video&quot;&gt;
    &lt;span class=&quot;video&quot;&gt;
      &lt;iframe style=&quot;width:100%; height:100%;&quot; src=&quot;https://www.youtube.com/embed/MmOau-PMWJk&quot; loading=&quot;lazy&quot; allowfullscreen=&quot;&quot;&gt;
      &lt;/iframe&gt;
    &lt;/span&gt;
    &lt;figcaption class=&quot;caption&quot;&gt;sade is waifu&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;</content><author><name>Chris Carin</name></author><category term="Misc" /><category term="sade is waifu" /><summary type="html">If you don’t like this song, your life choices are incorrect. sade is waifu</summary></entry><entry><title type="html">Anatomy of Subtractive Synths</title><link href="http://0.0.0.0:4000/GRPH/audio/2021/12/03/anatomy-of-subtractive-synths.html" rel="alternate" type="text/html" title="Anatomy of Subtractive Synths" /><published>2021-12-03T00:00:00-05:00</published><updated>2021-12-03T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/audio/2021/12/03/anatomy-of-subtractive-synths</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/audio/2021/12/03/anatomy-of-subtractive-synths.html">&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#micron-signalpath-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/micron_signalpath.png&quot; alt=&quot;Signal path for the Alesis Micron&quot; style=&quot;width: 500px&quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Signal path for the Alesis Micron
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;micron-signalpath-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/micron_signalpath.png&quot; alt=&quot;Signal path for the Alesis Micron&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;As mentioned in my previous post, sound can be thought of as a signal. Synthesizers make the most of this fact by producing sound through the manipulation of signals. Despite the countless methods to manipulate signals, most synthesizers on the market follow a similar structure when it comes to the components that make it up. As a culmination of audio processes, most synthesizers can be can be described with the following signal path: &lt;strong&gt;Generator -&amp;gt; Filter -&amp;gt; Output&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This architecture is the basis of something called subtractive synthesis. It was initially popularized in the 70s by synthesizers like the &lt;a href=&quot;https://www.vintagesynth.com/moog/moog.php&quot;&gt;MiniMoog&lt;/a&gt;, the &lt;a href=&quot;https://www.vintagesynth.com/oberheim/obxa.php&quot;&gt;OB-Xa&lt;/a&gt;, and the &lt;a href=&quot;https://www.vintagesynth.com/korg/ms20.php&quot;&gt;MS-20&lt;/a&gt;. The idea behind subtractive synthesis is to take an already harmonically rich sound source and to sculpt it by attenuating it’s amplitude and frequency components overtime. Even though this architecture is catered towards a specific method of synthesis, this signal path is not limited to it. Because of its flexibility, most synths nowadays follow a similar architecture. The point of deviation is normally within the design of the generator and/or the filter.&lt;/p&gt;

&lt;p&gt;Traditionally, synthesizers like the MiniMoog were implemented with analog circuits. In contrast, my project is trying to emulate similar processes in a digital manner. To better understand these processes, I’m dedicating this post to briefly go over the standard audio processing components of a synthesizer mentioned above.&lt;/p&gt;

&lt;h2 id=&quot;generators&quot;&gt;Generators&lt;/h2&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float right&quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#waveform-gif&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/waveform.gif&quot; alt=&quot;Basic Wave Shapes&quot; style=&quot;width: 120px&quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Basic Wave Shapes
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;waveform-gif&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/waveform.gif&quot; alt=&quot;Basic Wave Shapes&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;As the name implies, a generator is a function which generates a signal. Normally synths use oscillators as a primary source of generation. Oscillators are functions that produce periodic (repeating) signals such as sine waves and sawtooth waves, as mentioned in previous posts. The parameters of an oscillator normally control its shape and relative pitch. What these parameters are vary depending on design on the oscillator. Oscillators are not necessarily limited to basic wave shapes. They can really take any complex shape a user desires, though it’s important to keep aliasing in mind when creating custom wave shapes. An example of a non-standard oscillator would be the &lt;a href=&quot;/GRPH/audio/2021/10/14/fft_grainspec.html&quot;&gt;time-stretching phase vocoder&lt;/a&gt; I put together in Pd.&lt;/p&gt;

&lt;p&gt;Though most use one or more oscillators as a generator, there are synths out there which don’t use any sort of periodic function generator. A common example are synths which use pre-recorded sounds as their audio generation source such as the &lt;a href=&quot;https://www.soundonsound.com/reviews/mellotron-mkvi&quot;&gt;Mellotron&lt;/a&gt;. These kinds of instruments often border on sampler territory in their feature set and capabilities. A less common method of non-periodic audio generation is through use of digital waveguides to emulate physical models. A very basic example of this would be the &lt;a href=&quot;https://ccrma.stanford.edu/~jos/pasp/Karplus_Strong_Algorithm.html&quot;&gt;Karplus-Strong algorithm&lt;/a&gt;. This territory is a bit beyond the scope of this project so I won’t talk about it much. Instead, I offer &lt;a href=&quot;https://www.youtube.com/watch?v=ppx72p27JNU&quot;&gt;this&lt;/a&gt; video for more information if you’re interested. I may talk about Karplus-Strong later however.&lt;/p&gt;

&lt;h2 id=&quot;filters&quot;&gt;Filters&lt;/h2&gt;

&lt;p&gt;Filters are functions which are used to alter the phase and/or frequency components within a signal. While there many different types of filters, the ones most commonly found on synthesizers are low-pass, high-pass, and band-pass. The function of these filters can more or less be deduced by their name.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#filter-types-jpg&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/filter_types.jpg&quot; alt=&quot;Basic Filter Types&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Basic Filter Types
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;filter-types-jpg&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/filter_types.jpg&quot; alt=&quot;Basic Filter Types&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;A low-pass attenuates frequencies above a given cutoff frequency, only allowing lower frequencies through. A high-pass does the opposite. These two filters are normally controlled by a cutoff and resonance parameters. Cutoff controls the maximum/minimum frequency to be passed by filter. Resonance controls amplitude gain at the cutoff point.&lt;/p&gt;

&lt;p&gt;A band-pass attenuates frequencies the further away they are from a set center band. They can be thought of as the combination of both a highpass and lowpass filter. Band-pass filters are normally controlled using a center and Q parameter. The center controls the center of the passband, while the q controls the passband’s width.&lt;/p&gt;

&lt;p&gt;Below is a video demo of the filters mentioned above. The original Pd patch for this example can be found &lt;a href=&quot;/GRPH/assets/other/filter_example.zip&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;!-- Include for Video Embedding --&gt;
&lt;!-- https://github.com/nathancy/jekyll-embed-video#responsive-videos --&gt;
&lt;div class=&quot;float&quot;&gt;
  &lt;figure class=&quot;embed video&quot;&gt;
    &lt;span class=&quot;video&quot;&gt;
      &lt;iframe style=&quot;width:100%; height:100%;&quot; src=&quot;https://player.vimeo.com/video/653521212?h=b0a124d5cc&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; loading=&quot;lazy&quot; allowfullscreen=&quot;&quot;&gt;
      &lt;/iframe&gt;
    &lt;/span&gt;
    &lt;figcaption class=&quot;caption&quot;&gt;Demonstration of a low-pass, high-pass, and band-pass filter.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Less commonly found on synthesizers are band-stop (aka notch) filters. Band-stops attenuate frequencies the closer they are to a given frequency band. They can be thought of as the inverse of a band-pass. Other kinds of filters include shelving, peaking, all-pass, and comb filters. The first two are normally found in EQs, while the latter two are normally used as diffusers and resonators for delay type effects. I won’t go in detail about the frequency response of these filters, but do know they exist. I may or may not elaborate on them later if needed.&lt;/p&gt;

&lt;h2 id=&quot;control-signals&quot;&gt;Control Signals&lt;/h2&gt;

&lt;p&gt;As mentioned in the introduction, control signals are signals used to automate parameters. There are two types commonly found on most synthesizers: LFOs and envelopes.&lt;/p&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed audio&quot; style=&quot;width: &quot;&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/tremolo.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/vibrato.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;figcaption&gt;An example of pitch (above) and volume (below) modulation via LFO&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;LFOs (Low Frequency Oscillators) are oscillators used to automate parameters. The ‘LF’ refers to the fact that these oscillators are typically set to frequencies below the range of human hearing. Because oscillators are periodic, they can be useful for creating a sense of motion when used to automate parameters. For example applying an LFO to the pitch of a generator will create a tremolo like effect. Applying it to volume will create something like vibrato.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#adsrenvelope-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/adsrenvelope.png&quot; alt=&quot;Diagram of an ADSR envelopes output value and stages over time&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Diagram of an ADSR envelopes output value and stages over time
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;adsrenvelope-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/adsrenvelope.png&quot; alt=&quot;Diagram of an ADSR envelopes output value and stages over time&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;Envelopes are a type of non-periodic signal which normally reset each time a user inputs a new note. They can be thought of as a sequence of points which are output over set-able amount of time. Most envelopes have four parameters which correspond to its stages of change over time. These are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Attack - The time it takes for a signal to reach peak value from resting value.&lt;/li&gt;
  &lt;li&gt;Decay - The time it takes for a signal to decay to the sustain value after reaching its peak.&lt;/li&gt;
  &lt;li&gt;Sustain - The value to hold when as a note while is active (post-decay stage)&lt;/li&gt;
  &lt;li&gt;Release - The time it takes for a signal to decay to resting value.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Prior to output, a synthesizer typically has a voltage controlled amplifier (VCA) for controlling the overall gain of the instrument. What makes the amplifier ‘voltage controlled’ is the fact that it is normally controlled by an envelope. This gives the user access to a large range of volume contours for their sound. To elaborate, below are some more audio examples demonstrating how an envelope can shape the volume contour.&lt;/p&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed audio&quot; style=&quot;width: &quot;&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/short_atk.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/long_atk_long_rel.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/short_rel.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;figcaption&gt;Three sound examples. The first has a short attack and long release, the second has a long attack and long release, the third has a long attack and short release&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;output&quot;&gt;Output&lt;/h2&gt;

&lt;p&gt;Post VCA, some synthesizers offer on-board effects such as distortions, delays, choruses, and reverbs. Effects can do a lot of things to sound. For example, distortions will usually thicken a sound by adding harmonic content. Delays cause an echoing effect which can turn into all sorts of wacky stuff when you start automating the parameters.&lt;/p&gt;

&lt;p&gt;I’m not sure if I’ll have the time or system resources to handle too many effects, but if I do manage to implement any of these things, I’ll definitely write a post elaborating on how so-and-so effect works. Otherwise, there’s way too many processes out there to go over in this post. If anything, check out this list of the different types of guitar pedal if you’re interested in seeing what kind of effects are out there in the world.&lt;/p&gt;</content><author><name>Chris Carin</name></author><category term="Audio" /><category term="Digital Synths" /><summary type="html">Signal path for the Alesis Micron</summary></entry><entry><title type="html">Due Dates and Blog Content</title><link href="http://0.0.0.0:4000/GRPH/misc/2021/12/03/due-dates-and-blog-content.html" rel="alternate" type="text/html" title="Due Dates and Blog Content" /><published>2021-12-03T00:00:00-05:00</published><updated>2021-12-03T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/misc/2021/12/03/due-dates-and-blog-content</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/misc/2021/12/03/due-dates-and-blog-content.html">&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; I have too much stuff to write about and not enough time to write it. In case I don’t finish, below is list of posts I still have drafted up. You can refer to this list for updates on these unfinished drafts. My goal is get all these up within a week of submission day at least.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Things that I want posted:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;del&gt;Anatomy of Subtractive Synths Pt. 2&lt;/del&gt; (Merged with part 1)&lt;/li&gt;
  &lt;li&gt;&lt;del&gt;Oscillator Design pt. 1: Anti-aliasing&lt;/del&gt;&lt;/li&gt;
  &lt;li&gt;Oscillator Design pt. 2: Waveshaping&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;I don’t think I’m going to be able to write all of the content I would like before Dec. 8th. Unfortunately, I have an essay due for another class on the exact same day. My goal for now is to finish my overview on synth anatomy and then quickly write about the code and design decisions I have finalized. While I do have a functioning synth engine on Bela, a lot of it is still underdeveloped and not exactly ready to be shared. The only things which have been finalized so far are the oscillator and the voice signal path.&lt;/p&gt;

&lt;p&gt;I realize now that it’s really hard to describe signal processing related things without falling back on jargon. I guess I take for granted how much I’ve internalized a lot of the terminology I would read about while obsessively researching things. It also doesn’t help that I feel like I struggle with writing in general. Even with this post, I’m constantly editing myself while I write. It’s horrible.&lt;/p&gt;

&lt;p&gt;Honestly, I don’t even think the amount content I have right now is bad. It’s just not everything I have to talk about which I feel is a little disappointing. Either way, if I fail to get these posts up by the 8th, I think I can at least get them written within the week of. The nice thing about blogs is that they can always be updated after the fact.&lt;/p&gt;</content><author><name>Chris Carin</name></author><category term="Misc" /><category term="Updates" /><summary type="html">TLDR: I have too much stuff to write about and not enough time to write it. In case I don’t finish, below is list of posts I still have drafted up. You can refer to this list for updates on these unfinished drafts. My goal is get all these up within a week of submission day at least.</summary></entry><entry><title type="html">Sampling Rates &amp;amp; Harmonics</title><link href="http://0.0.0.0:4000/GRPH/audio/2021/11/29/sample-rates-and-harmonics.html" rel="alternate" type="text/html" title="Sampling Rates &amp;amp; Harmonics" /><published>2021-11-29T00:00:00-05:00</published><updated>2021-11-29T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/audio/2021/11/29/sample-rates-and-harmonics</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/audio/2021/11/29/sample-rates-and-harmonics.html">&lt;p&gt;Before I continue, I want to disclose that I am not an engineer. I am merely an enthusiast who enjoys synthesis. This information may not be the most correct or academically rigorous. Much of what I’m writing about is my own self-educated understanding of these subjects. If I do make a mistake, please point it out to me in an email. So, I guess without further ado, &lt;em&gt;here we go…&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When working with sound on computers, it’s useful to become acquainted with how digital signals work. A signal is a function which varies over an independent variable (normally time). Sound can be thought of as a signal created through variations in air pressure over time. When we hear something, what we’re really sensing is physical vibration. When an audio waveform is drawn on screen, that vibration is what is represented.&lt;/p&gt;

&lt;p&gt;Electric and electronic devices normally produce sound using speakers. When a device is wired to a speaker through something like an AUX cable, it is sending a control signal to drive a speaker’s diaphragm. When such a signal reaches a speaker, an electromagnetic motor converts the signal into mechanical vibrations based on its voltage level. These vibrations create changes in air pressure to produce sound. This is of course a very abridged version of speakers work, but for our purposes it’s all we need to know. If you want to read more about speakers &lt;a href=&quot;https://animagraffs.com/loudspeaker/&quot;&gt;this page&lt;/a&gt; is pretty informative (warning: it contains a large infographic).&lt;/p&gt;

&lt;p&gt;To produce audio through a speaker, all that’s needed is an electrical signal strong enough to drive diaphragm. As mentioned in a previous post, I’m using a single board computer with a dedicated sound capelet to generate the audio signals for this project. It’s important to note how I’m generating these signals because signals in the digital domain are discrete. What I mean by discrete is best illustrated by discussing audio sample rates and quality.&lt;/p&gt;

&lt;h2 id=&quot;whats-a-discrete-signal&quot;&gt;What’s a Discrete Signal?&lt;/h2&gt;

&lt;p&gt;If you’ve heard of the term &lt;a href=&quot;https://blog.discmakers.com/2019/06/cds-just-sound-better/&quot;&gt;CD quality&lt;/a&gt;, you may also be aware that like digital images, digital audio has resolution. Rather than RGB values within a grid of pixels, digital audio can be thought of as a sequence of voltage levels over time. Each value in the sequence is known as a sample. When a digital device plays back audio, it runs through thousands of samples at a fixed rate to produce a composite signal for a speaker to convert into sound.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#digital-wave-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/digital_wave.png&quot; alt=&quot;Visual representation of audio in digital form&quot; style=&quot;width: 500px&quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Visual representation of audio in digital form
      
        &lt;br /&gt;(original image: http://grahammitchell.com/writings/vorbis_intro.html)
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;digital-wave-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/digital_wave.png&quot; alt=&quot;Visual representation of audio in digital form&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;Unlike their physical and analog counterparts, signals produced through digital means cannot have continuous fidelity. Rather, digital signals can be thought of as a countable series of states. This is basically what I mean when I use the term discrete. Think of it this way: when working with print, graphic designers often use units of length such as inches or millimeters as measurements of size. When designing for the digital domain however, graphic designers will instead measure by pixel. Conceptually, pixels and units of length are completely different. While there is such a thing as a fraction of an inch, there is no such thing as a fraction of a pixel. This same concept can be applied to sound by viewing audio signals as a function over time. Rather than counting by seconds however, we are instead counting by samples.&lt;/p&gt;

&lt;p&gt;Because of its discrete nature, there is a limited range of frequencies that a digital signal can reproduce accurately. &lt;a href=&quot;https://mathworld.wolfram.com/SamplingTheorem.html&quot;&gt;Sampling theorem&lt;/a&gt; states that the highest frequency a discrete system can represent is equal to the system’s sampling rate divided by 2. CD quality’s sampling rate is 44.1kHz, therefore the highest representable frequency at CD quality is 22.05kHz. This maximum frequency is known as the &lt;a href=&quot;https://mathworld.wolfram.com/NyquistFrequency.html&quot;&gt;Nyquist Frequency&lt;/a&gt; (or just Nyquist for short). Since the range of human hearing is between 20Hz-20kHz, CD quality is more than sufficient for casually playing back audio. For digital synthesis however, there are benefits to higher rates.&lt;/p&gt;

&lt;h2 id=&quot;the-relationship-between-timbre-and-sample-rate&quot;&gt;The Relationship between Timbre and Sample Rate&lt;/h2&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed audio&quot; style=&quot;width: &quot;&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/piano.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/sine.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;figcaption&gt;A piano (above) and a sine tone (below) playing middle A (440Hz)&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;It’s important to know about sampling rates because sound synthesis is really all about harmonic manipulation. To elaborate, I’ve posted two audio examples to the left (or above on mobile). One is the sound of a piano, the other is the sound of a sine tone slowly fading out. Both examples are playing middle A. If you compare the two, it’s easy to distinguish that they sound nothing alike. The reason for this is because the relationship of frequencies (aka the harmonics) produced by the sound of a piano key is much more complex than a single sine tone. The relationship between frequencies produced over time is what defines what is traditionally known as an instrument’s timbre.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#pianospek-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/pianospek.png&quot; alt=&quot;The frequency spectrum of a piano (left) and a sine tone (right) playing middle A (440Hz)&quot; style=&quot;width: 300px&quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;a href=&quot;#sinespek-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/sinespek.png&quot; alt=&quot;The frequency spectrum of a piano (left) and a sine tone (right) playing middle A (440Hz)&quot; style=&quot;width: 300px&quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      The frequency spectrum of a piano (left) and a sine tone (right) playing middle A (440Hz)
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;pianospek-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/pianospek.png&quot; alt=&quot;The frequency spectrum of a piano (left) and a sine tone (right) playing middle A (440Hz)&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;sinespek-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/sinespek.png&quot; alt=&quot;The frequency spectrum of a piano (left) and a sine tone (right) playing middle A (440Hz)&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;By graphing out the spectral components, we can confirm both the harmonic complexity of a piano (on the left), and the simplicity of the sine tone. In contrast to the piano, the sine tone contains only a single harmonic located at its fundamental frequency. This is true of all sine tones making sine waves the harmonically the simplest sound possible. Due to their harmonic simplicity, all periodic waveforms can be represented as a summation of multiple sine tones with varying frequencies, phases, and amplitudes. By extension, anything that isn’t a sine tone is going to have spectra more complex than a single sine wave. Should any of the harmonic components of a signal exceed Nyquist frequency, the signal becomes subject to a type of digital aliasing known as ‘foldover’. Any signal with a frequency above Nyquist will produce a mirrored component equal to Nyquist minus the difference of the original frequency and Nyquist.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#saw-sweep-spek-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/saw_sweep_spek.png&quot; alt=&quot;Spectogram of a niave sawtooth sweep&quot; style=&quot;width: 600px&quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Spectogram of a niave sawtooth sweep
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;saw-sweep-spek-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/saw_sweep_spek.png&quot; alt=&quot;Spectogram of a niave sawtooth sweep&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed audio&quot; style=&quot;width: &quot;&gt;
    
    &lt;audio controls=&quot;&quot;&gt;
      &lt;source src=&quot;/GRPH/assets/audio/saw_sweep.mp3&quot; type=&quot;audio/mp3&quot; loading=&quot;lazy&quot; /&gt;
      Your browser does not support the audio element.
    &lt;/audio&gt;
    
    &lt;figcaption&gt;Niave sawtooth sweep from 0Hz to 22.05kHz and back at a sampling rate of 44.1kHz&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;To demonstrate foldover, to the above is an audio example of a naively generated sawtooth wave sweeping from 0Hz to 22.05kHz at a sample rate of 44.1kHz. If you pay close attention, a swirling distortion becomes prevalent as the sweep approaches Nyquist. To visualize foldover I’ve posted a spectrogram of the audio recording. Notice how harmonics seem to reflect back and forth between 0Hz and Nyquist as they fall out of range. While this effect can sound interesting in some situations (I like it on hi-hats), it’s unwanted in most. I don’t exactly want to go into detail as to why fold over occurs (this post is already almost 1000 words long), so I will instead defer to &lt;a href=&quot;http://www.dspguide.com/ch3/2.htm&quot;&gt;this resource&lt;/a&gt; for more information.&lt;/p&gt;

&lt;p&gt;What I’m trying to get across is that it’s important to understand what digital audio is when working with low-level audio synthesis. Without such knowledge, it’s easy to end up with consistently poor-quality sounds. Even at increased sample rates, it’s easy to end up with something distorted when you aren’t taking harmonic content into account. For my situation, I don’t even really have access to higher sample rates. The Bela board is actually locked to a 44.1kHz sample rate. While this isn’t entirely ideal, there are implementable methods to reduce aliasing which I plan to go over in future posts as needed.&lt;/p&gt;</content><author><name>Chris Carin</name></author><category term="Audio" /><category term="Digital Synths" /><summary type="html">Before I continue, I want to disclose that I am not an engineer. I am merely an enthusiast who enjoys synthesis. This information may not be the most correct or academically rigorous. Much of what I’m writing about is my own self-educated understanding of these subjects. If I do make a mistake, please point it out to me in an email. So, I guess without further ado, here we go…</summary></entry><entry><title type="html">The Web is Obese</title><link href="http://0.0.0.0:4000/GRPH/website/2021/11/20/the-web-is-obese.html" rel="alternate" type="text/html" title="The Web is Obese" /><published>2021-11-20T00:00:00-05:00</published><updated>2021-11-20T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/website/2021/11/20/the-web-is-obese</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/website/2021/11/20/the-web-is-obese.html">&lt;p&gt;Despite what minimalist trends prevalent throughout the tech industries may have you believe, today’s modern web is very bloated. Just &lt;a href=&quot;https://www.wired.com/2016/04/average-webpage-now-size-original-doom/&quot;&gt;5 years ago&lt;/a&gt;, the average web page was already larger than the original DOOM for MS-DOS. In reaction to this, I choose to design this blog to be as lightweight and easy to load as possible. I remember times back in High School where my computer could barely handle 3 or 4 tabs of Chrome or Firefox. It was awful. Since then, modern
web browsers have implemented a plethora of new features and in turn have become potentially bigger resource hogs. And just as they do, designers While these features provide a lot of creative power to web designers, it’s part of the designer’s job to wield these powers appropriately.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#nocss-frontpage-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/nocss_frontpage.png&quot; alt=&quot;What a software minimal website does look like&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      What a software minimal website does look like
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;nocss-frontpage-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/nocss_frontpage.png&quot; alt=&quot;What a software minimal website does look like&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;Just to be clear, I’m not claiming page weight and efficiency always need to be prioritized over other aspects of page design. If we were to prioritize software minimalism over all other things, most sites on the web would look like &lt;a href=&quot;https://nocss.club/&quot;&gt;this&lt;/a&gt;. If that is the internet you prefer, you’re probably better off switching to the &lt;a href=&quot;http://gopher.quux.org:70/&quot;&gt;gopher protocol&lt;/a&gt; or something. There are also plenty of in browser scenarios that require access to advanced scripting functionalities. Full office suites like Google Docs wouldn’t exist without such things.&lt;/p&gt;

&lt;p&gt;I’m suggesting there is a balance that needs to be respected when it comes designing for content on the modern web. Just because we can do something fancy and resource expensive, doesn’t mean we always should. If we think of a page on the web as small pieces of software, the content would be the main process of application. The content is the main reason why any given visitor is on any given web page. It is what the user is attempting to execute when they visit. By bloating up the interface to this process, a designer runs the risk needlessly increasing the number of resources required to load and display the content. Not only does this make content harder to access for certain users (particularly those on mobile and lower end devices), but it also increases a page’s environmental footprint.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#ocadu-frontpage-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/ocadu_frontpage.png&quot; alt=&quot;What a software minimal website does not look like&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      What a software minimal website does not look like
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;ocadu-frontpage-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/ocadu_frontpage.png&quot; alt=&quot;What a software minimal website does not look like&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;Let’s look at &lt;a href=&quot;https://ocadu.ca/&quot;&gt;OCADU’s homepage&lt;/a&gt; for example. I noticed it features a video which automatically loads up every time someone visits it. To me, this is already a problem. While the use of videos as splash elements have become more popular on today’s web, it is a trend that I heavily disagree with. Landing pages are meant to be quick, flexible, and easy to navigate. They need to be because they are literally the index of the rest of the website. Embedded videos are the opposite of these characteristics. They are large, slow, and often break at different resolutions.&lt;/p&gt;

&lt;p&gt;Below is part of the results provided by &lt;a href=&quot;https://tools.pingdom.com/&quot;&gt;Pingdom’s speed tool&lt;/a&gt;:&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#ocadu-size-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/ocadu_size.png&quot; alt=&quot;Size of OCADs front page, sorted by file type&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Size of OCADs front page, sorted by file type
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;ocadu-size-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/ocadu_size.png&quot; alt=&quot;Size of OCADs front page, sorted by file type&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;As we can see above, OCAD’s front page is over 20MB. And of course, most of that weight is the video the school decided to embed. If I were bandwidth limited or data capped, opening this home page would eat a significant chunk of my available transfer for the month. Furthermore, if I were to access this page from an older computer, it would probably take up the entirety of the computer’s processing power just to display it.&lt;/p&gt;

&lt;p&gt;Beyond accessibility however, there is an environmental cost to having a heavy website. According to &lt;a href=&quot;https://www.websitecarbon.com/&quot;&gt;Wholegrain Digital&lt;/a&gt;, every GB costs about &lt;a href=&quot;https://www.websitecarbon.com/how-does-it-work/&quot;&gt;1.8kW of electricity an hour&lt;/a&gt;. If we do the math, that means OCADU’s front page costs approximately 0.03533kWh for each un-cached visitor. If we multiply that with the total number of students at OCADU it would cost 214.52kWh for each student at OCAD to visit the index page once.&lt;/p&gt;

&lt;p&gt;Moving away from the video, we can also see that at most the HTML content of the page is about 0.13% of overall transfer. That means of the 20MB required to load the page, at most 0.13% is written content. A majority of the remaining 8%~ are scripts and stylesheets. If we look at the source, we can kind of see why.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot; data-lang=&quot;html&quot;&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;preload&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/_nuxt/1c029e12983acd1547a7.js&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;as=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;script&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;preload&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/_nuxt/0b76837911f386b4e84d.js&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;as=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;script&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;preload&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/_nuxt/8fda144dac918648a67b.css&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;as=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;style&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;preload&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/_nuxt/a19306e62382a80f9692.js&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;as=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;script&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;preload&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/_nuxt/364a65052d6aaed82138.css&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;as=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;style&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;preload&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/_nuxt/cbeb1be2886825385048.js&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;as=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;script&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stylesheet&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/_nuxt/8fda144dac918648a67b.css&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stylesheet&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/_nuxt/364a65052d6aaed82138.css&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Though I don’t really have much of a basis to question these pre-loaded scripts, I do wonder why a simple index page would need so many. It seems like each one of these scripts has a CSS file paired with. This leads me to believe each JS file is a definition for an embedded application. If they are applications, I’m not really sure what they do. My hunch is that it’s for web analytics. Either way, pre-loading this much stuff is not exactly ideal especially in the case of scripts. Pre-loading a script forces the user’s browser to process said scripts before it begins to load the page. This obviously complexifies and slows down the initial process. Also, since these are externally linked files, secondary requests must be made before they can be loaded. Essentially, it’s forcing you to load some other crap before you can get actual content you’re requesting. This can be obviously useful in a lot of scenarios, but again it’s something not to be abused.&lt;/p&gt;

&lt;p&gt;So yeah, OCAD’s homepage sucks. It’s slow and bloated and kind of broken at times. And it’s not just OCAD’s homepage that sucks. There are plenty of other examples of web pages out there which are way heavier than they need to be. It’s like an electronic epidemic. So if you ever design a website, please keep performance at least somewhat in mind. Think about what is necessary for the content. Adding too much to a web page will not only bog down/break a user’s access, it’s also just straight up worse for the environment.&lt;/p&gt;</content><author><name>Chris Carin</name></author><category term="Website" /><category term="Web Design" /><category term="Nonsense" /><summary type="html">Despite what minimalist trends prevalent throughout the tech industries may have you believe, today’s modern web is very bloated. Just 5 years ago, the average web page was already larger than the original DOOM for MS-DOS. In reaction to this, I choose to design this blog to be as lightweight and easy to load as possible. I remember times back in High School where my computer could barely handle 3 or 4 tabs of Chrome or Firefox. It was awful. Since then, modern web browsers have implemented a plethora of new features and in turn have become potentially bigger resource hogs. And just as they do, designers While these features provide a lot of creative power to web designers, it’s part of the designer’s job to wield these powers appropriately.</summary></entry><entry><title type="html">Thoughts on why I’m making a synthesizer</title><link href="http://0.0.0.0:4000/GRPH/audio/2021/11/16/why-im-making-a-synth.html" rel="alternate" type="text/html" title="Thoughts on why I’m making a synthesizer" /><published>2021-11-16T00:00:00-05:00</published><updated>2021-11-16T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/audio/2021/11/16/why-im-making-a-synth</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/audio/2021/11/16/why-im-making-a-synth.html">&lt;p&gt;When it comes to actually writing music, I actually think I’m pretty awful. I spend so much time obsessing over tiny details and always have a hard time seeing the big picture of what I’m trying to do. Honestly, the reason why I’ve been so upset with my process of creation is due to this indecisiveness to move on from minute details. On top of that, I’m not the most mechanically gifted person in the world. Much like how I struggle with brushes and inks, I can barely play inversions on the piano.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#sonic-pi-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/sonic-pi.png&quot; alt=&quot;Screenshot of Sonic Pi from Wikipedia&quot; style=&quot;width: 800px&quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Screenshot of Sonic Pi from Wikipedia
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;sonic-pi-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/sonic-pi.png&quot; alt=&quot;Screenshot of Sonic Pi from Wikipedia&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;When it came to design however, I always thought what gave me an edge is my ability to pull magic out of computers. While there was a lot I needed to learn at OCAD to feel even remotely competent with what I was doing, I always felt like I had this talent as a crux. I call it magic because I really think computers are magical. Here is this box. You can put whatever data in it you can think of and with just a little bit of a math you can shape that data into (&lt;a href=&quot;https://www.youtube.com/watch?v=macM_MtS_w4&quot;&gt;almost&lt;/a&gt;) any virtual form you want. If that’s not magic, I don’t know what is. I think that’s what attracted me to electronic music in the first place. I always wanted to make music. I just never had the patience to figure out how to physically play something.&lt;/p&gt;

&lt;p&gt;I remember when I first started playing with sound, I was using this program called &lt;a href=&quot;https://sonic-pi.net/&quot;&gt;Sonic Pi&lt;/a&gt; to make beats while on commutes. In retrospect, Sonic Pi is amazing and I really oughta pick it up again. It’s basically a music sequencing environment based around live coding. At the time however, I wasn’t really interested in the idea of live performance. While sequencing in Sonic Pi was awesome, it felt a bit limiting to be stuck with same set off instruments. While the option existed to load up custom instruments made in &lt;a href=&quot;https://supercollider.github.io/&quot;&gt;SuperCollider&lt;/a&gt;, at the time I found SuperCollider was a little beyond me. After a couple weeks I moved on to PureData hoping for something simple to learn that gave me better control of timbre.&lt;/p&gt;

&lt;p&gt;If anyone is to ever ask me what my favourite programming language is, my answer would probably be &lt;a href=&quot;https://puredata.info/&quot;&gt;PureData&lt;/a&gt;. Never in my life have I tried so hard to learn everything I could about a piece of software. When I first picked it up, I would spend weeks building simple samplers and shitty noise generators. I didn’t make any music out of it, but I felt like I was learning so much out of just playing around as awful as those sounds were. What amazed me was how sounds could be generated with such modularity. How everything and anything could be defined as a value and how that value can be generated in anyway you want.&lt;/p&gt;

&lt;!-- Include for Video Embedding --&gt;
&lt;!-- https://github.com/nathancy/jekyll-embed-video#responsive-videos --&gt;
&lt;div class=&quot;float&quot;&gt;
  &lt;figure class=&quot;embed video&quot;&gt;
    &lt;span class=&quot;video&quot;&gt;
      &lt;iframe style=&quot;width:100%; height:100%;&quot; src=&quot;https://player.vimeo.com/video/646396827?h=b0a124d5cc&amp;amp;badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot; loading=&quot;lazy&quot; allowfullscreen=&quot;&quot;&gt;
      &lt;/iframe&gt;
    &lt;/span&gt;
    &lt;figcaption class=&quot;caption&quot;&gt;A Pd track I made a couple months ago&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Eventually I began dissecting other user patches to better understand how to build things like fancy oscillators and simple audio effects. This led me to start reading up and researching audio processing techniques. One particular resource I always mention that I found really useful is Miller Puckette’s &lt;a href=&quot;http://msp.ucsd.edu/techniques/v0.11/book-html/&quot;&gt;Theory and Techniques of Electronic Music&lt;/a&gt;. It features plenty of examples of various audio processing algorithms and is written by the guy who created Pd. I think part of me believed that by understanding these sound processes on a deeper level, I would unlock some sort of understanding of the kind of music I wanted to make. Obviously, this didn’t come true and I still have no idea what I’m doing. At multiple points however, I believed it enough to coax myself into attempting to build my own &lt;a href=&quot;https://en.wikipedia.org/wiki/Eurorack&quot;&gt;eurorack&lt;/a&gt;-style system for algorithmic music. Every time I tried though, my system would end up being overly complexed and too much of a hassle to play. On top of that, I often found Pd’s small selection of basic UI options to be quite limiting when trying to make something substantial.&lt;/p&gt;

&lt;p&gt;Ultimately, my experience with Pd is kind of what drives me to make this electronic instrument for my workshop project. Though I still I don’t really know much of anything about music (I don’t even know much about computers tbh), I do know how to make sounds using software. I haven’t decided on how I want the this instrument to play or look like just yet, but I’m hoping by shifting my focus a bit to a single tangible thing I can at least come up with something interesting and fun to play.&lt;/p&gt;</content><author><name>Chris Carin</name></author><category term="Audio" /><category term="Music" /><category term="PureData" /><category term="Nonsense" /><summary type="html">When it comes to actually writing music, I actually think I’m pretty awful. I spend so much time obsessing over tiny details and always have a hard time seeing the big picture of what I’m trying to do. Honestly, the reason why I’ve been so upset with my process of creation is due to this indecisiveness to move on from minute details. On top of that, I’m not the most mechanically gifted person in the world. Much like how I struggle with brushes and inks, I can barely play inversions on the piano.</summary></entry><entry><title type="html">New Layout!</title><link href="http://0.0.0.0:4000/GRPH/website/2021/11/14/new-layout.html" rel="alternate" type="text/html" title="New Layout!" /><published>2021-11-14T00:00:00-05:00</published><updated>2021-11-14T00:00:00-05:00</updated><id>http://0.0.0.0:4000/GRPH/website/2021/11/14/new-layout</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/website/2021/11/14/new-layout.html">&lt;p&gt;Over the last couple days I’ve been kind of taking a break from programming the Bela in order to focus my attention on this blog. Despite aiming for a lightweight website, I made a few compromises by deciding to use javascript and webfonts for the sake of style. After testing the website on an &lt;a href=&quot;https://www.cnet.com/products/acer-aspire-one-d250/specs/&quot;&gt;old netbook&lt;/a&gt; however, I noticed that even having a minimal amount of scripting was a bit too much. On top of that, further testing showed that the typefaces imported by Google fonts accounted for the a majority of my sites digital weight.&lt;/p&gt;

&lt;h2 id=&quot;issues-with-the-old-layout&quot;&gt;Issues with the Old Layout&lt;/h2&gt;

&lt;p&gt;Prior to the re-design, the main thing I was using JS for was to show and hide my menu items. If you’re interested in how that works, the source code for the previous version of the site can be found &lt;a href=&quot;https://github.com/cheesoup/GRPH/tree/bf5ac20a3080064854d65529b38d4fbd6abc8bad&quot;&gt;here&lt;/a&gt; (thank God for git). The unfortunate thing with CSS and JS animations however is that they’re pretty CPU intensive. Whenever I would open the menu on the netbook, the fans would whirl and the CPU usage would shoot up to 97%.&lt;/p&gt;

&lt;p&gt;Other than the menu, I also implemented some JS for placing arbitrary text into someone’s copy and paste clipboard. I was mainly using to create hyperlinks which would give the user the URL to the RSS feed. Though the script does work pretty well, if JS is disabled for whatever reason it is impossible to access the RSS. Also I feel like using JS in this way was sort of lazy.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#blog-size-0-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/blog_size_0.png&quot; alt=&quot;34.1kbs for webfonts&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      34.1kbs for webfonts
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;blog-size-0-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/blog_size_0.png&quot; alt=&quot;34.1kbs for webfonts&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;After getting rid of all the javascript, I found a few &lt;a href=&quot;https://pagespeed.web.dev/&quot;&gt;online&lt;/a&gt; &lt;a href=&quot;https://tools.pingdom.com/&quot;&gt;tools&lt;/a&gt; for measuring how much data a webpage requests whenever it is loaded. As the results above show, webfonts had previously accounted for over 50% of the site’s bandwidth per visit which for me is obviously not cool. To remedy this, I stuck to &lt;a href=&quot;https://www.cssfontstack.com/&quot;&gt;web safe fonts&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;on-to-the-new&quot;&gt;On to the New&lt;/h2&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float right&quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#splash-gif&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/../splash.gif&quot; alt=&quot;Say hi!&quot; style=&quot;width: &quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      Say hi!
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;splash-gif&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/../splash.gif&quot; alt=&quot;Say hi!&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;I’m pretty happy about is how small this website is. I’ve managed to get the about my main pages below &lt;a href=&quot;https://pagespeed.web.dev/report?url=https%3A%2F%2Fcheesoup.github.io%2FGRPH%2Fabout&quot;&gt;20kbs&lt;/a&gt;! I think that’s pretty impressive. There are actually still a few things I would like to implement (the main thing being a pure CSS lightbox for photos), but I think that’s a project for another day.&lt;/p&gt;

&lt;p&gt;Other than optimization, I had a couple goals in mind when working on the re-design. I have a process book coming up for Workshop and I figured starting here would be a good place for coming up with design ideas for the final printed version. I guess visually, I’m really trying to pull ideas from WEB 1.0. Part of me is nostalgic for the hours I would spend listening to the midi re-interpretations of Koji Kondo’s Dire Dire Docks or Alice Deejay’s Better Off Alone on Geocities.&lt;/p&gt;

&lt;p&gt;If you haven’t noticed, I’ve come up with a little mascot for this project. You can see them up in the top corner! They don’t quite have a name yet, but they’re my buddy and we’re gonna make synths together. They’re based off a friend of mine from Calgary who makes some pretty rad tunes and actually isn’t a crow (their last name just sounds like it).&lt;/p&gt;</content><author><name>Chris Carin</name></author><category term="Website" /><category term="Updates" /><category term="Web Design" /><summary type="html">Over the last couple days I’ve been kind of taking a break from programming the Bela in order to focus my attention on this blog. Despite aiming for a lightweight website, I made a few compromises by deciding to use javascript and webfonts for the sake of style. After testing the website on an old netbook however, I noticed that even having a minimal amount of scripting was a bit too much. On top of that, further testing showed that the typefaces imported by Google fonts accounted for the a majority of my sites digital weight.</summary></entry><entry><title type="html">Coding on bela</title><link href="http://0.0.0.0:4000/GRPH/audio/2021/10/26/coding-on-bela.html" rel="alternate" type="text/html" title="Coding on bela" /><published>2021-10-26T00:00:00-04:00</published><updated>2021-10-26T00:00:00-04:00</updated><id>http://0.0.0.0:4000/GRPH/audio/2021/10/26/coding-on-bela</id><content type="html" xml:base="http://0.0.0.0:4000/GRPH/audio/2021/10/26/coding-on-bela.html">&lt;p&gt;&lt;del&gt;I finally managed to get sometime to do a bit a programming. It’s been alright so far. Most of my times been spent on figuring out how pointers work and just getting used to C++ in general. I managed to program this dithered polyBLEP sawtooth oscillator. It’s a bit late so I’ll edit this post later with some details on the code, but for now here it is in raw form.&lt;/del&gt;&lt;br /&gt;
&lt;strong&gt;[Oct.30th edit: OK LETS WRITE SOME STUFF]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ok so before I write about my code, I guess I should probably write about what Bela is and basic Bela programming. &lt;a href=&quot;https://www.bela.io&quot;&gt;Bela&lt;/a&gt; is a cape for the &lt;a href=&quot;https://beagleboard.org/black&quot;&gt;Beagle Bone Black&lt;/a&gt; single board computer. It specializes in audio processing for the purpose of creating audio effects, instruments, sound installations, whatever. It comes with 16 digital and analog IOs for interfacing with switches and potentiometers and stuff. It’s pretty rad.&lt;/p&gt;

&lt;h2 id=&quot;rendercpp&quot;&gt;render.cpp&lt;/h2&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;Bela.h&amp;gt;
#include &amp;lt;cmath&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gFrequency&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;440.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gInverseSampleRate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BelaContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;gInverseSampleRate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;audioSampleRate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;render&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BelaContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;audioFrames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sinf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M_PI&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gFrequency&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gInverseSampleRate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M_PI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M_PI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;audioOutChannels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;audioWrite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cleanup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BelaContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;


&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Above is the basic example code shipped with Bela. It produces a sine wave signal at 440hz (middle A). Other than being based in C++ rather than Java, it’s surprisingly similar to Processing in terms of having a setup() function followed by some looping rendering function. The functions are given two arguments: a pointer to a BelaContext object, a pointer to a userData object. From what I assume/read online, these objects declared in the Bela.h header file and contain system data such as hardware and driver information.&lt;/p&gt;

&lt;h2 id=&quot;setup&quot;&gt;setup()&lt;/h2&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BelaContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;gInverseSampleRate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;audioSampleRate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Unlike Processing, Bela’s setup function returns a boolean. The render loop won’t start unless setup() returns true. In the example provided, the setup function initializes a few variables. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gInverseSampleRate&lt;/code&gt; is set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1 / samplerate&lt;/code&gt; and while &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gPhase&lt;/code&gt; is initialized to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;.&lt;/p&gt;

&lt;!-- Include for captioned images --&gt;

&lt;div class=&quot;float &quot;&gt;
  &lt;figure class=&quot;embed picture&quot; style=&quot;width: &quot;&gt;
    
    &lt;a href=&quot;#sine-png&quot;&gt;
      &lt;img src=&quot;/GRPH/assets/images/content/sine.png&quot; alt=&quot;A plot of a sine function with its phase normalized to 2π&quot; style=&quot;width: 800px&quot; loading=&quot;lazy&quot; /&gt;
    &lt;/a&gt;
    
    &lt;figcaption&gt;
      A plot of a sine function with its phase normalized to 2π
      
    &lt;/figcaption&gt;
  &lt;/figure&gt;
  
  &lt;a href=&quot;#/&quot; class=&quot;expand&quot; id=&quot;sine-png&quot;&gt;
    &lt;img src=&quot;/GRPH/assets/images/content/sine.png&quot; alt=&quot;A plot of a sine function with its phase normalized to 2π&quot; style=&quot;background-image: url(&apos;/GRPH/assets/images/transparent.gif&apos;)&quot; loading=&quot;lazy&quot; /&gt;
  &lt;/a&gt;
  
&lt;/div&gt;

&lt;p&gt;When graphing a periodic (repeating) waveform statically like the image above, phase can be described as the current x-value (between 0-1) of the wave. As the x-value increments, the waveform’s y-value oscillates between -1 and 1. To apply this idea to audio, we have think of x as something that is constantly accumulating between 0-1. This is pretty much what Bela’s example code does.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;render&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BelaContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;audioFrames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sinf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M_PI&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gFrequency&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gInverseSampleRate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M_PI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;gPhase&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M_PI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;audioOutChannels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;audioWrite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The amount to increment x is calculated by multiplying the given frequency by the inverse sample rate. This is equal to ` dx = freq / samplerate`. By controlling how much we increment the phase, we’re able to control the frequency at which the oscillator oscillates at. Something to keep in mind with this example however is that they normalize the phase to 2PI. This is because the normal phase length of a sine wave is 2PI.&lt;/p&gt;

&lt;h2 id=&quot;cleanup&quot;&gt;cleanup()&lt;/h2&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cleanup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BelaContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;userData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This section doesn’t actually do anything. In C++, one is able to dynamically allocate memory. When doing so, memory needs to be deallocated to free it up again. Dynamic memory allocation isn’t used in this example however, thus nothing needs to be cleaned up. In scenarios where you do dynamically allocate memory, this is where you would deallocate the remainder of what needs to be deallocated.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;And that’s all the example does! Hopefully this post wasn’t too wordy. If you’re interested in learning more about audio programming in C++, I’ve been following this &lt;a href=&quot;https://www.youtube.com/watch?v=aVLRUyPBBJk&quot;&gt;YouTube tutorial&lt;/a&gt;. I think it’s pretty useful even outside of a Bela context. I’m not quite sure how easy it is to follow for non-programmers and people not into signal processing however.&lt;/p&gt;</content><author><name>Chris Carin</name></author><category term="Audio" /><category term="Programming" /><category term="Bela" /><category term="Oscillators" /><summary type="html">I finally managed to get sometime to do a bit a programming. It’s been alright so far. Most of my times been spent on figuring out how pointers work and just getting used to C++ in general. I managed to program this dithered polyBLEP sawtooth oscillator. It’s a bit late so I’ll edit this post later with some details on the code, but for now here it is in raw form. [Oct.30th edit: OK LETS WRITE SOME STUFF]</summary></entry></feed>